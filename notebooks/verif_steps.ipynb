{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from matplotlib import colormaps\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import random\n",
    "import typer\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_recall_curve, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, label_binarize\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from skimage import exposure\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.feature import hog, local_binary_pattern, corner_harris, corner_subpix, corner_peaks\n",
    "\n",
    "from scipy.ndimage import gaussian_filter, gaussian_laplace, sobel\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PATHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJ_ROOT = Path().resolve().parents[0]\n",
    "\n",
    "DATA_DIR = PROJ_ROOT / \"data\"\n",
    "RAW_DATA_DIR = DATA_DIR / \"raw\"\n",
    "EXTERNAL_DATA_DIR = DATA_DIR / \"external\"\n",
    "\n",
    "MODELS_DIR = PROJ_ROOT / \"models/tmp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path: Path = RAW_DATA_DIR / \"cifar-10-batches-py\"\n",
    "data_path: Path = EXTERNAL_DATA_DIR / \"processed_dataset.pkl\"\n",
    "predictions_path: Path = EXTERNAL_DATA_DIR / \"test_predictions.csv\"\n",
    "model_path: Path = MODELS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURES AND DATA PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path, encoding=None):\n",
    "    \"\"\"\n",
    "    Load data from a pickle file\n",
    "\n",
    "    Args:\n",
    "        file_path: str\n",
    "    \"\"\"\n",
    "    with open(file_path, 'rb') as f:\n",
    "        if (encoding is not None):\n",
    "            data = pickle.load(f, encoding=encoding)\n",
    "        else:\n",
    "            data = pickle.load(f)\n",
    "    return data\n",
    "\n",
    "def save_data(data, file):\n",
    "    \"\"\"\n",
    "    Save data to a pickle file\n",
    "\n",
    "    Args:\n",
    "        data: any\n",
    "        file: str\n",
    "    \"\"\"\n",
    "    with open(file, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "def to_image(img_flat):\n",
    "    \"\"\"\n",
    "    Convert a flattened image to a 3D image\n",
    "\n",
    "    Args:\n",
    "        img_flat: np.ndarray\n",
    "    \"\"\"\n",
    "    img_R = img_flat[0:1024].reshape((32, 32))\n",
    "    img_G = img_flat[1024:2048].reshape((32, 32))\n",
    "    img_B = img_flat[2048:3072].reshape((32, 32))\n",
    "    img = np.dstack((img_R, img_G, img_B))\n",
    "    return img\n",
    "\n",
    "def image_contrast(image):\n",
    "    \"\"\"\n",
    "    Compute the contrast of an image\n",
    "\n",
    "    Args:\n",
    "        image: np.ndarray\n",
    "    \"\"\"\n",
    "    lab= cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a, b = cv2.split(lab)\n",
    "\n",
    "    # Applying CLAHE to L-channel\n",
    "    # feel free to try different values for the limit and grid size:\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "\n",
    "    # Converting image from LAB Color model to BGR color spcae\n",
    "    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "    return enhanced_img\n",
    "\n",
    "def extract_hog_features(images):\n",
    "    \"\"\"\n",
    "    Extract HOG features from a list of images\n",
    "\n",
    "    Args:\n",
    "        images: np.ndarray\n",
    "    \"\"\"\n",
    "    hog_features = []\n",
    "\n",
    "    for image in images:\n",
    "        gray_image = rgb2gray(image).astype(np.uint8)\n",
    "        # hog_image_rescaled = exposure.rescale_intensity(gray_image, in_range=(0, 10))\n",
    "        feature, hog_image = hog(gray_image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, channel_axis=None, multichannel=False, block_norm='L2-Hys')\n",
    "        # feature, hog_image = hog(hog_image_rescaled, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, channel_axis=None, multichannel=False, block_norm='L2-Hys')\n",
    "        hog_features.append(feature)\n",
    "\n",
    "    return np.array(hog_features)\n",
    "\n",
    "def extract_sift_features(images):\n",
    "    \"\"\"\n",
    "    Extract SIFT features from a list of images\n",
    "\n",
    "    Args:\n",
    "        images: np.ndarray\n",
    "    \"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    sift_features = []\n",
    "\n",
    "    for image in images:\n",
    "        gray_image = rgb2gray(image).astype(np.uint8)\n",
    "        # print(image.shape, gray_image.shape, image.dtype, gray_image.dtype)\n",
    "        keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "        if descriptors is None:\n",
    "            sift_features.append(np.zeros((128,)))\n",
    "        else:\n",
    "            sift_features.append(descriptors.flatten())\n",
    "    \n",
    "    return np.array(sift_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import sample\n",
    "\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "import progressbar as pb\n",
    "\n",
    "\n",
    "class VLAD:\n",
    "    \"\"\"VLAD - Vector of Locally Aggregated Descriptors\n",
    "\n",
    "    This class provides an implementation of the original proposal of \"Vector of Locally Aggregated Descriptors\" (VLAD)\n",
    "    originally proposed in [1]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    k : int, default=256\n",
    "        Number of clusters to obtain for the visual vocabulary.\n",
    "    n_vocabs : int, default=1\n",
    "        Number of vocabularies to use\n",
    "    norming : {\"original\", \"intra\", \"RN\"}, default=\"original\"\n",
    "        How the norming of the VLAD-descriptors should be performed.\n",
    "        For more info see below.\n",
    "    lcs : bool, default=True\n",
    "        If `True`, uses Local Coordinate System (LCS) described in [3]_.\n",
    "    alpha : float, default=0.2\n",
    "        The exponent for the root-part, default taken from [3]_\n",
    "    verbose : bool, default=True\n",
    "        If `True` print messages here and there\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    vocabs : sklearn.cluster.KMeans(k)\n",
    "        The visual vocabulary of the object\n",
    "    centers : array\n",
    "        The centroids for the visual vocabulary\n",
    "    database : array\n",
    "        All known VLAD-vectors\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    ``norming=\"original\"`` uses the original formulation of [1]_. An updated formulation based on [2]_\n",
    "    is provided by ``norming=\"intra\"``. Finally the best norming based on [3]_ is provided by ``norming=\"RN\"``.\n",
    "\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Jégou, H., Douze, M., Schmid, C., & Pérez, P. (2010, June). Aggregating\n",
    "           local descriptors into a compact image representation. In 2010 IEEE computer\n",
    "           society conference on computer vision and pattern recognition (pp. 3304-3311). IEEE.\n",
    "\n",
    "    .. [2] Arandjelovic, R., & Zisserman, A. (2013). All about VLAD. In Proceedings of the\n",
    "           IEEE conference on Computer Vision and Pattern Recognition (pp. 1578-1585).\n",
    "\n",
    "    .. [3] Delhumeau, J., Gosselin, P. H., Jégou, H., & Pérez, P. (2013, October).\n",
    "           Revisiting the VLAD image representation. In Proceedings of the 21st ACM\n",
    "           international conference on Multimedia (pp. 653-656).\n",
    "\n",
    "    .. [4] Jégou, H., & Chum, O. (2012, October). Negative evidences and co-occurences in image\n",
    "           retrieval: The benefit of PCA and whitening. In European conference on computer vision\n",
    "           (pp. 774-787). Springer, Berlin, Heidelberg.\n",
    "\n",
    "    .. [5] Spyromitros-Xioufis, E., Papadopoulos, S., Kompatsiaris, I. Y., Tsoumakas, G., & Vlahavas,\n",
    "           I. (2014). A comprehensive study over VLAD and product quantization in large-scale image retrieval.\n",
    "           IEEE Transactions on Multimedia, 16(6), 1713-1728.\n",
    "    \"\"\"\n",
    "    def __init__(self, k=256, n_vocabs=1, norming=\"original\", lcs=False, alpha=0.2, verbose=True):\n",
    "        \"\"\"Initialize VLAD-object\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "\n",
    "        Hyperparameters have to be set, even if `centers` and `qs` are set externally.\n",
    "        \"\"\"\n",
    "        self.k = k\n",
    "        self.n_vocabs = n_vocabs\n",
    "        self.norming = norming\n",
    "        self.vocabs = None\n",
    "        self.centers = None\n",
    "        self.database = None\n",
    "        self.lcs = lcs\n",
    "        self.alpha = alpha\n",
    "        self.qs = None\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Fit Visual Vocabulary\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list(array)\n",
    "            List of image descriptors\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : VLAD\n",
    "            Fitted object\n",
    "        \"\"\"\n",
    "        X_mat = np.vstack(X)\n",
    "        self.vocabs = []\n",
    "        self.centers = []  # Is a list of `n_vocabs` np.arrays. Can be set externally without fitting\n",
    "        self.qs = []  # Is a list of `n_vocabs` lists of length `k` of np.arrays. Can be set externally without fitting\n",
    "        for i in range(self.n_vocabs):\n",
    "            if self.verbose is True:\n",
    "                print(f\"Training vocab #{i+1}\")\n",
    "            if self.verbose is True:\n",
    "                print(f\"Training KMeans...\")\n",
    "            if len(X_mat) < int(2e5):\n",
    "                self.vocabs.append(KMeans(n_clusters=self.k).fit(X_mat))\n",
    "            else:\n",
    "                idx = sample(range(len(X_mat)), int(2e5))\n",
    "                self.vocabs.append(KMeans(n_clusters=self.k).fit(X_mat[idx]))\n",
    "            self.centers.append(self.vocabs[i].cluster_centers_)\n",
    "            if self.lcs is True and self.norming == \"RN\":\n",
    "                if self.verbose is True:\n",
    "                    print(\"Finding rotation-matrices...\")\n",
    "                predicted = self.vocabs[i].predict(X_mat)\n",
    "                qsi = []\n",
    "                for j in range(self.k):\n",
    "                    q = PCA(n_components=X_mat.shape[1]).fit(X_mat[predicted == j]).components_\n",
    "                    qsi.append(q)\n",
    "                self.qs.append(qsi)\n",
    "        self.database = self._extract_vlads(X)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"Transform the input-tensor to a matrix of VLAD-descriptors\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list(array)\n",
    "            List of image-descriptors\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        vlads : array, shape (n, d * self.k)\n",
    "            The transformed VLAD-descriptors\n",
    "        \"\"\"\n",
    "        vlads = self._extract_vlads(X)\n",
    "        return vlads\n",
    "\n",
    "    def fit_transform(self, X, y):\n",
    "        \"\"\"Fit the model and transform the input-data subsequently\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list(array)\n",
    "            List of image-descriptors\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        vlads : array, shape (n, d * self.k)\n",
    "            The transformed VLAD-descriptors\n",
    "        \"\"\"\n",
    "        _ = self.fit(X, y)\n",
    "        vlads = self.transform(X)\n",
    "        return vlads\n",
    "\n",
    "    def refit(self, X):\n",
    "        \"\"\"Refit the Visual Vocabulary\n",
    "\n",
    "        Uses the already learned cluster-centers as in initial values for\n",
    "        the KMeans-models\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array\n",
    "            The database used to refit the visual vocabulary\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        self : VLAD\n",
    "            Refitted object\n",
    "        \"\"\"\n",
    "        self.vocabs = []\n",
    "        self.centers = []\n",
    "\n",
    "        for i in range(self.n_vocabs):\n",
    "            self.vocabs.append(KMeans(n_clusters=self.k, init=self.centers).fit(X.transpose((2, 0, 1))\n",
    "                                                                                .reshape(-1, X.shape[1])))\n",
    "            self.centers.append(self.vocabs[i].cluster_centers_)\n",
    "\n",
    "        self.database = self._extract_vlads(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, desc):\n",
    "        \"\"\"Predict class of given descriptor-matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        desc : array\n",
    "            A descriptor-matrix (m x d)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ``argmax(self.predict_proba(desc))`` : array\n",
    "        \"\"\"\n",
    "        return np.argmax(self.predict_proba(desc))\n",
    "\n",
    "    def predict_proba(self, desc):\n",
    "        \"\"\"Predict class of given descriptor-matrix, return probability\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        desc : array\n",
    "            A descriptor-matrix (m x d)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ``self.database @ vlad``\n",
    "            The similarity for all database-classes\n",
    "        \"\"\"\n",
    "        vlad = self._vlad(desc)  # Convert to VLAD-descriptor\n",
    "        return self.database @ vlad  # Similarity between L2-normed vectors is defined as dot-product\n",
    "\n",
    "    def _vlad(self, X):\n",
    "        \"\"\"Construct the actual VLAD-descriptor from a matrix of local descriptors\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array\n",
    "            Descriptor-matrix for a given image\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ``V.flatten()`` : array\n",
    "            The VLAD-descriptor\n",
    "        \"\"\"\n",
    "        np.seterr(invalid='ignore', divide='ignore')  # Division with 0 encountered below\n",
    "        vlads = []\n",
    "\n",
    "        for j in range(self.n_vocabs):  # Compute for multiple vocabs\n",
    "            # predicted = self.vocabs[j].predict(X)  # Commented out in favor of line below (No dependency on actual vocab, but only on centroids)\n",
    "            predicted = norm(X - self.centers[j][:, None, :], axis=-1).argmin(axis=0)\n",
    "            _, d = X.shape\n",
    "            V = np.zeros((self.k, d))  # Initialize VLAD-Matrix\n",
    "\n",
    "            # Computing residuals\n",
    "            if self.norming == \"RN\":\n",
    "                curr = X - self.centers[j][predicted]\n",
    "                curr /= norm(curr, axis=1)[:, None]\n",
    "                # Untenstehendes kann noch vektorisiert werden\n",
    "\n",
    "                for i in range(self.k):\n",
    "                    V[i] = np.sum(curr[predicted == i], axis=0)\n",
    "                    if self.lcs is True:\n",
    "                        V[i] = self.qs[j][i] @ V[i]  # Equivalent to multiplication in  summation above\n",
    "            else:\n",
    "                for i in range(self.k):\n",
    "                    V[i] = np.sum(X[predicted == i] - self.centers[j][i], axis=0)\n",
    "\n",
    "            # Norming\n",
    "            if self.norming in (\"intra\", \"RN\"):\n",
    "                V /= norm(V, axis=1)[:, None]  # L2-normalize every sum of residuals\n",
    "                np.nan_to_num(V, copy=False)  # Some of the rows contain 0s. np.nan will be inserted when dividing by 0!\n",
    "\n",
    "            if self.norming in (\"original\", \"RN\"):\n",
    "                V = self._power_law_norm(V)\n",
    "\n",
    "            V /= norm(V)  # Last L2-norming\n",
    "            V = V.flatten()\n",
    "            vlads.append(V)\n",
    "        vlads = np.concatenate(vlads)\n",
    "        vlads /= norm(vlads)  # Not on axis, because already flat\n",
    "        return vlads\n",
    "\n",
    "    def _extract_vlads(self, X):\n",
    "        \"\"\"Extract VLAD-descriptors for a number of images\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : list(array)\n",
    "            List of image-descriptors\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        database : array\n",
    "            Database of all VLAD-descriptors for the given Tensor\n",
    "        \"\"\"\n",
    "        vlads = []\n",
    "        if self.verbose:\n",
    "            for x in pb.progressbar(X):\n",
    "                vlads.append(self._vlad(x))\n",
    "        else:\n",
    "            for x in X:\n",
    "                vlads.append(self._vlad(x))\n",
    "\n",
    "        database = np.vstack(vlads)\n",
    "        return database\n",
    "\n",
    "    def _add_to_database(self, vlad):\n",
    "        \"\"\"Add a given VLAD-descriptor to the database\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        vlad : array\n",
    "            The VLAD-descriptor that should be added to the database\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        ``None``\n",
    "        \"\"\"\n",
    "        self.database = np.vstack((self.database, vlad))\n",
    "\n",
    "    def _power_law_norm(self, X):\n",
    "        \"\"\"Perform power-Normalization on a given array\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array\n",
    "            Array that should be normalized\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        normed : array\n",
    "            Power-normalized array\n",
    "        \"\"\"\n",
    "        normed = np.sign(X) * np.abs(X)**self.alpha\n",
    "        return normed\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"VLAD(k={self.k}, norming=\\\"{self.norming}\\\")\"\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"VLAD(k={self.k}, norming=\\\"{self.norming}\\\")\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHODS FOR MODELS LOADING & SAVING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, model_dir='models'):\n",
    "    \"\"\"\n",
    "    Save the trained model to a file.\n",
    "    \n",
    "    Args:\n",
    "        model: Trained model to be saved.\n",
    "        model_name: The name of the model file.\n",
    "        model_dir: Directory where the model will be saved.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    \n",
    "    file_path = os.path.join(model_dir, model_name)\n",
    "    joblib.dump(model, file_path)\n",
    "    print(f\"Model saved to {file_path}\")\n",
    "\n",
    "def load_model(model_name, model_dir='models'):\n",
    "    \"\"\"\n",
    "    Load a trained model from a file.\n",
    "    \n",
    "    Args:\n",
    "        model_name: The name of the model file.\n",
    "        model_dir: Directory where the model is saved.\n",
    "    \n",
    "    Returns:\n",
    "        Loaded model.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(model_dir, model_name)\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"No model found at {file_path}\")\n",
    "    \n",
    "    model = joblib.load(file_path)\n",
    "    print(f\"Model loaded from {file_path}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Processing dataset...\")\n",
    "meta_dict = load_data(input_path / \"batches.meta\", encoding='bytes')\n",
    "label_names = meta_dict[b'label_names']\n",
    "print(f\"Labels/Features: {label_names}\")\n",
    "\n",
    "combined_dict = {\n",
    "    b'data': [],\n",
    "    b'labels': [],\n",
    "    b'label_names': label_names,\n",
    "    b'hog_data': [],\n",
    "    b'validation_data': [],\n",
    "    b'validation_labels': [],\n",
    "    b'validation_hog_data': [],\n",
    "    b'test_data': [],\n",
    "    b'test_labels': [],\n",
    "    b'test_hog_data': [],\n",
    "    b'sample_images': {label: [] for label in label_names}\n",
    "}\n",
    "\n",
    "for i in range(5):\n",
    "    batch_dict = load_data(input_path / f\"data_batch_{i+1}\", encoding='bytes')\n",
    "    combined_dict[b'data'].extend(batch_dict[b'data'])\n",
    "    combined_dict[b'labels'].extend(batch_dict[b'labels'])\n",
    "\n",
    "# Diviser les données en données d'entraînement et de validation\n",
    "combined_dict[b'data'], combined_dict[b'validation_data'], combined_dict[b'labels'], combined_dict[b'validation_labels'] = train_test_split(\n",
    "    combined_dict[b'data'], combined_dict[b'labels'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Charger les données de test depuis test_batch\n",
    "test_batch_dict = load_data(input_path / \"test_batch\", encoding='bytes')\n",
    "combined_dict[b'test_data'].extend(test_batch_dict[b'data'])\n",
    "combined_dict[b'test_labels'].extend(test_batch_dict[b'labels'])\n",
    "\n",
    "# Sélectionner 10 images aléatoires pour chaque classe\n",
    "for label_index, label in enumerate(label_names):\n",
    "    label_indices = [i for i, lbl in enumerate(combined_dict[b'labels']) if lbl == label_index]\n",
    "    sample_indices = random.sample(label_indices, 10)\n",
    "    for idx in sample_indices:\n",
    "        combined_dict[b'sample_images'][label].append(combined_dict[b'data'][idx])\n",
    "\n",
    "save_data(combined_dict, data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA DICTIONARY KEYS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'random_forest': RandomForestClassifier(random_state=42, criterion='entropy', max_depth=10), # criterion, max_depth\n",
    "    'svm': SVC(max_iter=100 , kernel='rbf', random_state=42), # degree, gamma\n",
    "    'logistic_regression': LogisticRegression(random_state=42), # penalty, solver\n",
    "    'knn': KNeighborsClassifier(), # n_neighbors, algorithm\n",
    "    # 'gradient_boosting': GradientBoostingClassifier(learning_rate=0.01, random_state=42) # loss, max_depth, criterion\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "class ImageFlattener(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X.reshape(X.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('grayscale', FunctionTransformer(rgb2gray, validate=False)),\n",
    "    # ('flatten', ImageFlattener()),\n",
    "    # ('sift_extraction', FunctionTransformer(extract_sift_features, validate=False)),\n",
    "    # ('hog_extraction', FunctionTransformer(extract_hog_features, validate=False)),\n",
    "    ('vlad', VLAD(k=16, norming=\"RN\")),\n",
    "    # ('scaler', StandardScaler()),\n",
    "    # ('pca', PCA(n_components=10)),\n",
    "    ('classifier', None)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TRAINING & EVALUATING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(data[b'data']).reshape(-1, 32, 32, 3) / 255.0\n",
    "X_train = X_train.reshape(X_train.shape[0], -1)\n",
    "y_train = np.array(data[b'labels'])\n",
    "X_train = np.array([to_image(img) for img in X_train])\n",
    "\n",
    "\n",
    "train_dict = {\n",
    "    b'data': X_train,\n",
    "    b'labels': y_train,\n",
    "}\n",
    "save_data(train_dict, EXTERNAL_DATA_DIR / \"train_data.pkl\")\n",
    "\n",
    "X_validation = np.array(data[b'validation_data']).reshape(-1, 32, 32, 3) / 255.0\n",
    "X_validation = X_validation.reshape(X_validation.shape[0], -1)\n",
    "y_validation = np.array(data[b'validation_labels'])\n",
    "X_validation = np.array([to_image(img) for img in X_validation])\n",
    "\n",
    "\n",
    "validation_dict = {\n",
    "    b'data': X_validation,\n",
    "    b'labels': y_validation,\n",
    "}\n",
    "save_data(validation_dict, EXTERNAL_DATA_DIR / \"validation_data.pkl\")\n",
    "\n",
    "# Train the models\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} model...\")\n",
    "    pipeline.set_params(classifier=model)\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print(f\"{name} model trained.\")\n",
    "\n",
    "    y_pred = pipeline.predict(X_validation)\n",
    "\n",
    "    accuracy = accuracy_score(y_validation, y_pred)\n",
    "    print(f\"{name} model accuracy: {accuracy:.2f}\")\n",
    "\n",
    "    save_model(model, f\"{name}_model.pkl\", model_path)\n",
    "    print(f\"{name} model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.array(data[b'test_data']).reshape(-1, 32, 32, 3) / 255.0\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "X_test_2d = X_test\n",
    "y_test = np.array(data[b'test_labels'])\n",
    "X_test = np.array([to_image(img) for img in X_test])\n",
    "\n",
    "test_dict = {\n",
    "    b'data': X_test,\n",
    "    b'labels': y_test,\n",
    "}\n",
    "save_data(test_dict, EXTERNAL_DATA_DIR / \"test_data.pkl\")\n",
    "\n",
    "predictions = {'True Labels': y_test}\n",
    "\n",
    "# Evaluate the models\n",
    "for name, _ in models.items():\n",
    "    model = load_model(f'{name}_model.pkl', model_path)\n",
    "    print(f\"Evaluating {name} model...\")\n",
    "\n",
    "    test_pipeline = Pipeline([\n",
    "        ('greyscale', FunctionTransformer(rgb2gray, validate=False)),\n",
    "        # ('flatten', ImageFlattener()),\n",
    "        # ('sift_extraction', FunctionTransformer(extract_sift_features, validate=False)),\n",
    "        # ('hog_extraction', FunctionTransformer(extract_hog_features, validate=False)),\n",
    "        ('vlad', VLAD(k=16, norming=\"RN\")),\n",
    "        # ('scaler', StandardScaler()),\n",
    "        # ('pca', PCA(n_components=10)),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "\n",
    "    y_pred = test_pipeline.predict(X_test)\n",
    "    predictions[name] = y_pred\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{name} model accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "    scores = cross_val_score(model, X_test_2d, y_test, cv=5)\n",
    "    print(f\"{name} model cross-validation accuracy: {scores.mean():.2f}\")\n",
    "\n",
    "predictions_df = pd.DataFrame(predictions)\n",
    "predictions_df.to_csv(predictions_path, index=False)\n",
    "print(f\"Predictions saved to {predictions_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRAPH PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Histogram of Colors feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_color_histo_features(image, save_path=None):\n",
    "    gray_image = rgb2gray(image)\n",
    "\n",
    "    _, axis = plt.subplots(2, 2, gridspec_kw={'width_ratios': [1, 3]})\n",
    "    \n",
    "    # Grascale Image\n",
    "    axis[1][0].imshow(gray_image, cmap='gray')\n",
    "    axis[1][1].set_title('Histogram')\n",
    "    axis[1][0].set_title('Grayscale Image')\n",
    "    axis[1][0].axis('off')\n",
    "    hist = exposure.histogram(gray_image)\n",
    "    axis[1][1].plot(hist[0])\n",
    "\n",
    "    # Color image\n",
    "    if image.ndim == 3:\n",
    "        axis[0][0].imshow(image, cmap='gray')\n",
    "        axis[0][1].set_title('Histogram')\n",
    "        axis[0][0].set_title('Original Image')\n",
    "        axis[0][0].axis('off')\n",
    "        rgbcolors = ['red', 'green', 'blue']\n",
    "        for i, mycolor in enumerate(rgbcolors):\n",
    "            axis[0][1].plot(exposure.histogram(image[...,i])[0], color=mycolor)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "sample_image = X_train[np.random.randint(0, X_train.shape[0])]\n",
    "plot_color_histo_features(sample_image, \"../reports/color_histo_features.png\")\n",
    "\n",
    "# sample_image = X_train[0]\n",
    "# plot_color_histo_features(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot HOG feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hog_features(image, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot the HOG features of an image.\n",
    "\n",
    "    Args:\n",
    "        image: The image to plot the HOG features.\n",
    "        save_path: The path to save the plot.\n",
    "    \"\"\"\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    gray_image = rgb2gray(image)\n",
    "\n",
    "    # Extraire les caractéristiques HOG de l'image\n",
    "    feature, hog_image = hog(gray_image, pixels_per_cell=(8, 8), cells_per_block=(2, 2), visualize=True, channel_axis=None, block_norm='L2-Hys')\n",
    "    \n",
    "    # Normaliser l'image HOG\n",
    "    # hog_image_rescaled = exposure.rescale_intensity(hog_image, in_range=(0, 10)) # L'image est déjà normalisée au préalable\n",
    "    \n",
    "    # Afficher l'image originale et l'image HOG\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    axs[0].imshow(image)\n",
    "    axs[0].set_title('Original Image')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    axs[1].imshow(hog_image)\n",
    "    axs[1].set_title('HOG Image')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    axs[2].imshow(hog_image, cmap='gray')\n",
    "    axs[2].set_title('HOG Image with grayscale')\n",
    "    axs[2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "sample_image = X_train[np.random.randint(0, X_train.shape[0])]\n",
    "plot_hog_features(sample_image, \"../reports/hog_features.png\")\n",
    "\n",
    "# sample_image = X_train[0]\n",
    "# plot_hog_features(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot SIFT features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sift_features(image, save_path=None):\n",
    "    \"\"\"\n",
    "    Plots the original image, grayscale image, keypoints on grayscale image, and final image with keypoints overlaid.\n",
    "    \n",
    "    Args:\n",
    "        image: The input image as a numpy array.\n",
    "        save_path: The path to save the plot.\n",
    "    \"\"\"\n",
    "    # Convertir l'image en niveaux de gris\n",
    "    gray_image = (rgb2gray(image) * 255).astype(np.uint8)\n",
    "    image_8bit = (image * 255).astype(np.uint8)\n",
    "\n",
    "    # Initialisation du détecteur de points clés SIFT\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Détection des points clés et calcul des descripteurs\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_image, None)\n",
    "\n",
    "    # Afficher les points clés sur l'image originale\n",
    "    image_with_keypoints = cv2.drawKeypoints(image_8bit, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    # Afficher les points clés sur l'image en niveaux de gris\n",
    "    gray_image_with_keypoints = cv2.drawKeypoints(gray_image, keypoints, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "    \n",
    "    # Afficher les images: originale, en niveaux de gris, en niveaux de gris avec les points clés, et originale avec les points clés\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    \n",
    "    axs[0][0].imshow(image)\n",
    "    axs[0][0].set_title('Original Image')\n",
    "    axs[0][0].axis('off')\n",
    "\n",
    "    axs[0][1].imshow(gray_image, cmap='gray')\n",
    "    axs[0][1].set_title('Grayscale Image')\n",
    "    axs[0][1].axis('off')\n",
    "        \n",
    "    axs[1][0].imshow(image_with_keypoints)\n",
    "    axs[1][0].set_title('Image with SIFT Keypoints')\n",
    "    axs[1][0].axis('off')\n",
    "                   \n",
    "    axs[1][1].imshow(gray_image_with_keypoints)\n",
    "    axs[1][1].set_title('Grayscale Image with SIFT Keypoints')\n",
    "    axs[1][1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "sample_image = X_train[np.random.randint(0, X_train.shape[0])]\n",
    "plot_sift_features(sample_image, \"../reports/sift_features.png\")\n",
    "\n",
    "# sample_image = X_train[0]\n",
    "# plot_sift_features(sample_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corner detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corner_detect_features(image, save_path=None):\n",
    "    \"\"\"\n",
    "    Plot the corner detection features of an image.\n",
    "\n",
    "    Args:\n",
    "        image: The image to plot the corner detection features.\n",
    "        save_path: The path to save the plot.\n",
    "    \"\"\"\n",
    "    \n",
    "    gray_image = rgb2gray(image)\n",
    "    image = (image * 255).astype(np.uint8)\n",
    "\n",
    "    coords = corner_peaks(corner_harris(gray_image), min_distance=2, threshold_rel=0.01)\n",
    "    coords_subpix = corner_subpix(gray_image, coords, window_size=4)\n",
    "\n",
    "    fig, axis = plt.subplots(2, 2, figsize=(6, 6))\n",
    "    axis[0][0].axis('off')\n",
    "    axis[0][0].imshow(image)\n",
    "    axis[0][0].plot(\n",
    "        coords[:, 1], coords[:, 0], color='cyan', marker='o', linestyle='None', markersize=6\n",
    "    )\n",
    "    axis[0][0].plot(coords_subpix[:, 1], coords_subpix[:, 0], '+r', markersize=15)\n",
    "\n",
    "    axis[0][1].axis('off')\n",
    "    axis[0][1].imshow(gray_image, cmap='gray')\n",
    "    axis[0][1].plot(\n",
    "        coords[:, 1], coords[:, 0], color='cyan', marker='o', linestyle='None', markersize=6\n",
    "    )\n",
    "    axis[0][1].plot(coords_subpix[:, 1], coords_subpix[:, 0], '+r', markersize=15)\n",
    "    \n",
    "    # ----------- Contrasted Image ------------\n",
    "    contrasted_image = image_contrast(image)\n",
    "    gray_contrasted_image = rgb2gray(contrasted_image)\n",
    "\n",
    "    coords2 = corner_peaks(corner_harris(gray_image), min_distance=2, threshold_rel=0.01)\n",
    "    coords_subpix2 = corner_subpix(gray_image, coords2, window_size=4)\n",
    "\n",
    "    axis[1][0].axis('off')\n",
    "    axis[1][0].imshow(contrasted_image)\n",
    "    axis[1][0].plot(\n",
    "        coords2[:, 1], coords2[:, 0], color='cyan', marker='o', linestyle='None', markersize=6\n",
    "    )\n",
    "    axis[1][0].plot(coords_subpix2[:, 1], coords_subpix2[:, 0], '+r', markersize=15)\n",
    "\n",
    "    axis[1][1].axis('off')\n",
    "    axis[1][1].imshow(gray_contrasted_image, cmap='gray')\n",
    "    axis[1][1].plot(\n",
    "        coords2[:, 1], coords2[:, 0], color='cyan', marker='o', linestyle='None', markersize=6\n",
    "    )\n",
    "    axis[1][1].plot(coords_subpix2[:, 1], coords_subpix2[:, 0], '+r', markersize=15)\n",
    "    \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "sample_image = X_train[np.random.randint(0, X_train.shape[0])]\n",
    "plot_corner_detect_features(sample_image, \"../reports/corner_detect_features.png\")\n",
    "\n",
    "# sample_image = X_train[0]\n",
    "# plot_corner_detect_features(sample_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_df = pd.read_csv(predictions_path)\n",
    "data = load_data(data_path)\n",
    "label_names = [label.decode('utf-8') for label in data[b'label_names']]\n",
    "\n",
    "train_data = load_data(EXTERNAL_DATA_DIR / \"train_data.pkl\")\n",
    "test_data = load_data(EXTERNAL_DATA_DIR / \"test_data.pkl\")\n",
    "\n",
    "X_train = np.array(train_data[b'data'])\n",
    "y_train = np.array(train_data[b'labels'])\n",
    "X_test = np.array(test_data[b'data'])\n",
    "y_test = np.array(test_data[b'labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations, Matrices de Confusion, Courbe Precision-Recall, Courbes ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation des prédictions\n",
    "correlation_matrix = predictions_df.corr()\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title('Correlation Matrix of Model Predictions')\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='plasma')\n",
    "plt.show()\n",
    "\n",
    "n_classes = len(label_names)\n",
    "y_test_bin = label_binarize(y_test, classes=np.arange(n_classes))\n",
    "\n",
    "# Matrice de confusion\n",
    "for name, _ in models.items():\n",
    "    print(\"=============================================================\")\n",
    "    print(f\"Plotting evaluation metrics for {name}...\")\n",
    "    predictions = predictions_df[name]\n",
    "    cmat = confusion_matrix(y_test, predictions)\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.title(f'Confusion Matrix for {name}')\n",
    "    plt.xticks(rotation=45)\n",
    "    sns.heatmap(cmat, annot=True, fmt='d', cmap='Blues', xticklabels=label_names, yticklabels=label_names)\n",
    "    plt.xlabel('Predicted Labels')\n",
    "    plt.ylabel('True Labels')\n",
    "    plt.show()\n",
    "\n",
    "    # Courbes de précision/rappel et ROC\n",
    "    preds_bin = label_binarize(predictions, classes=np.arange(n_classes))\n",
    "    \n",
    "    # Precision-Recall curve\n",
    "    plt.figure()\n",
    "    for i, label in enumerate(label_names):\n",
    "        precision, recall, _ = precision_recall_curve(y_test_bin[:, i], preds_bin[:, i])\n",
    "        plt.plot(recall, precision, lw=2, label=f'{label}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall curve for {name}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    # ROC curve\n",
    "    plt.figure()\n",
    "    for i, label in enumerate(label_names):\n",
    "        fpr, tpr, _ = roc_curve(y_test_bin[:, i], preds_bin[:, i])\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, lw=2, label=f'{label} (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title(f'ROC curve for {name}')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PLOT CLASSIFIER COMPARISON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.append(X_train, X_test, axis=0)\n",
    "y = np.append(y_train, y_test)\n",
    "\n",
    "figure = plt.figure(figsize=(27, 9))\n",
    "i = 1\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "cm = colormaps.get_cmap('tab10')\n",
    "cm_bright = ListedColormap([\"red\", \"blue\", \"green\", \"purple\", \"orange\", \"brown\", \"pink\", \"gray\", \"olive\", \"cyan\"])\n",
    "\n",
    "ax = plt.subplot(1, len(models) + 1, i)\n",
    "ax = plt.subplot(len(data), len(models) + 1, i)\n",
    "\n",
    "ax.set_title('Input data')\n",
    "ax.scatter(X_train[:,0], X_train[:,1], c=[(1,0,0)]*len(y_train), cmap=cm_bright, edgecolors='k')\n",
    "ax.scatter(X_test[:,0], X_test[:,1], c=y_test, cmap=cm_bright, edgecolors='k', alpha=0.6)\n",
    "ax.set_xlim(x_min, x_max)\n",
    "ax.set_ylim(y_min, y_max)\n",
    "ax.set_xticks(())\n",
    "ax.set_yticks(())\n",
    "i += 1\n",
    "\n",
    "for name, _ in models.items():\n",
    "    model = joblib.load(model_path / f'{name}_model.pkl')\n",
    "    score = model.score(X_test, y_test)\n",
    "\n",
    "    ax = plt.subplot(1, len(models) + 1, i)\n",
    "\n",
    "    ax.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap=cm_bright, edgecolors='k')\n",
    "    ax.scatter(X_test[:, 0], X_test[:, 1], c=y_test, cmap=cm_bright, edgecolors='k', alpha=0.6)\n",
    "    ax.set_xlim(x_min, x_max)\n",
    "    ax.set_ylim(y_min, y_max)\n",
    "    ax.set_xticks(())\n",
    "    ax.set_yticks(())\n",
    "    ax.set_title(f'{name} (score = {score:.2f})')\n",
    "    ax.text(x_max - 0.3, y_min + 0.3, (\"%.2f\" % score).lstrip(\"0\"),\n",
    "            size=15, horizontalalignment='right')\n",
    "    i += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
